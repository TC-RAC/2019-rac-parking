---
title: "Analysis Journal---RAC Parking Report Automation"
author: mz
output:
  pdf_document: default
---

# Saturday 9.3.2019

* Initialised public github repo.

* Setup folder structure, currenlty looks like this (output of `tree --charset=ascii -d`):
```
|-- code
|-- data
|   |-- 01-raw
|   |-- 02-interim
|   `-- 03-processed
|-- docs
|   |-- admin
|   |-- journal
|   `-- original-reports
|-- figures
`-- outputs
    |-- instructions
    |-- reports
    `-- technical-appendix
```

* available reports used for development, downloaded from RAC press website, pdfs stored in `/docs/original-reports`, see appendix for full table

Next steps: find data

# Thursday 14.3.2019

* Look through back reports available, saving all and saving links here, in appendix 1

* Start query file for Ivo. 

* OK, got all reports, despite missing years, it looks like most of the data is included in other reports as they have a window of usually 4 years previous that they include data for. 

* Now figure out data sources for England, and detail them 

* Outline typical England report

## England data requirements and availability?

* 2017/18 uses "MHCLG tables on parking income and expenditure"

This looks like the data [https://www.gov.uk/government/collections/local-authority-revenue-expenditure-and-financing](here). 

* For each year there is normally budget, provisional outturn and outturn data, the latter needs to be for individual local authorities, which does not seem to exist for 2007/08, but is available for all other years. 
* The files are grouped under the title *Local authority revenue expenditure and financing England: 2010 to 2011 individual local authority data - outturn* for each year
* The relevant Excel file is usually called `Revenue outturn RO2 (highways and transport services) + year.xls`.
* There are three columns we are interested in: expenditures, incomes and capital charges, these are usually on separate sheets. There is one of these for both on street and off street parking. So that's 6 columns in total.
* There are also summaries, but I don't need them, maybe only for manually double-checking.
* Appendix 2 lists all the files, their links, the number or rows (local authorities) in the table and the sheets on which the data can be found.
* TODO Add the starting row and the actual columns where the data in question can be found and I can write a funciton to extract the data automatically. 
* Download all `.xls` files to `/data/raw`

* "Earlier, councils also submitted budgets for the 2018-19financial year but on a less detailed basis." where are these budgets? Do I need to include them as well? Ah, yes.

* At one point the England data stops including capital charges..2013/14 is last one. This means current reports are less data rich, and if I stick to the brief, it means that the code won't be able to replicate the old reports. 
* At one point the Englad data starts including penalty charges for individual Local authorities, although the reports don't do anything special with that, just use the aggregates. 

* England totals do not include the national parks and the Nottingham levy. Not sure what to do with that!?

# Friday 15.3.2019

* OK, so England outturn data is tabled in Appendix 2.
* Now England Budget data
  + not in *Local authority revenue expenditure and financing tables*
  + under *Budget estimates of local authority revenue expenditure and financing for the financial year* the table *Revenue account budget (RA)* has the parking surplus down as 792, but the report says 782. There have been a few other differnces, not sure if these are typos/errors?
  
* download data into `\data\raw` and fill out appendix two table with relevant info. 
* careful because at one point there are capital charges and then not. So make sure you've got the correct column. Because these are sums, I would even set up a check?
* OK, England budget files are all saved and relevant info extracted manually. 
* Now back to outlining the England report as it stands.
* E17/18 says national park surplus is 1.7 million, sum of cells DF405:411 is 1.774. 
* Comparing Table 1 for E17/18 to excel file 17/18:
  + on street parking is all the same
  + off street parking: there is a discrepancy. Income is the same, but Leibling's expenditure value is higher than the Excel one (making the surplus lower): 362 vs 356?!
  
# Saturday 16.3.2019

* Comparing Table 1 for E17/18 to excel file 16/17
  + on street parking is all the same
  + off street parking: there is a discrepancy. Leibling's income is 693 vs 689 in the table, and Leibling's expenditures are are 349 vs 343 in the table. 
* Comparing Table 1 for E17/18 to excel file 15/16
  + on street parking is all the same
  + off street parking: there is a discrepancy. Leibling's income is 670 vs 674 in the table, and Leibling's expenditures are are 340 vs 337 in the table. 

* Trying to figure out where these discrepancies come from: It must be the nottingham workplace levy? Which I don't have data for. 
* Second thing, presumably the difference is also due to not including the national parks. Although I have the data for that, I cannot confirm, because I don't know the levy numbers. 

* TODO write (find) a funtion to convert excel column names to column numbers. 
* Oh, congestion charge data needs to be read as well, that's in a different couple of cells than what i've been looking at until now, so add that to the appendix. 


# Monday 18.3.2019

* Clean up queries for Ivo for England. 
* Look at Scotland data. 2015/16 is the last year with a report but the data on  [this link](https://www2.gov.scot/Topics/Statistics/Browse/Local-Government-Finance/PubScottishLGFStats] seems to go to 2016/17
* I'm looking at `Annex A by LA` excel files, which have LA level data. 
* OK, so data checking: compare surplusses in individual sheets of `sco-15-16.xlss` with table 9, parking surpluses in report 15/16. 
  + Edinburg is same, so is Glasgow, Dundee, Renfrewshire, Fife, South Lank, East Ayr, Highland, Argyle, Aberdeenshire, Angus, South Ary, Moray,Perth, Stirling, 
  + Aberdeen city is 4.89 vs 0?
  + If I add Aberdeen city form Leibling to the Excel totals get the Leibling totals for Surplus.OK 
* But if I add the Aberdeen city incomes to the Excel ones, it's still not enough. And same for expenditures... So there is another LA that has a discrepancy. 
  + Clackmanshire discrepancy: .014 -> .02, but that's minor, could be poor rounding.   + South Ayershire discrepancy: .0 -> .80
  + And of course Aberdeen city: .0 -> 9.20
  + This fixes the total income discrepancies. 
* OK, now for the expenditure discrepancies:
  + Aberdeen city: 0 -> 4.32 
  + South Ayershire expenditure discrepancy: -.327 -> .470
  + ANd these now also add up. 
* Start Scotish data query file for Ivo
* Start outline of Scotland report based on *newly discovered* 16/17 report
* Penalty notice charge data is apparenlty out of a scanned pdf in 2015/16.... And 16/18 data in a regular pdf. But perhaps the tabulizer package could help me out? Unfortunatley there are some sort of java issues in installing the package...
* solved issue using [this link](https://stackoverflow.com/questions/51256462/r-cannot-install-rjava-what-is-r-api-3-4/51267282#51267282), installed rJava, but first had to  also run `sudo R CMD javareconf`. This is presumably only an ubuntu issue, so should work fine on Windows. * Tried tabulizer on the 17/18 pdf and it works!

#### PNC data

*Decriminalised Parking Enforcement - Local Authorities - Income and Expenditure*

* pdf's exist for 2016/17 and 2017/18. Additionally a scanned pdf exists for 2013/14/15/16. All have:
  + a table of which LAs are doing DPE, and which are considering it etc, this is in the report
  + a table of PNC incomes. However this last table also has other incomes and expenditures in it, so you'd think it would match with the gov.sco data in the Excel tables, but it doesn't. SOme are quite close, e.g. Glasgow, but others not.   
* Added table of PCN data to the appendix, created table to summarise the sources. 

*Todo: outline scotland data. 

# Tuesday 19.3.2019

* Found the 16/17 scotland files, they're not under press, but under publications...
* Add them to app1
* Actually clean up the data source tables and move them to code, these are manual data entry files. 
* Saving the tables into rds? Probably, it is serialised, and as opposed to csv it retains the data types. Let's me cleanly load individual objects and assign then names, and there's no danger of overwriting an object of the same name. But is not human readable. 
* This also involves using here::here() to load the data in the child .rmd documents for the appendices. 

* **mapping England**: OK, so the data is for 353 "local authorities", or are they actually "councils"? Shapefiles seem to have 326 shapes. Wikipedia says there are 27 county and 201 district councils, *which cover the same physical area*. plus 55 UAs, 36 met burroughs and 32 London ones, plus the city, plus scilly. But they overlap..
* SO e.g. you have Oxford council and Oxfodshire council. The first only does off street parking, while the county one does both. Do I add them up? If I want to map them I have to. But in the tables are they separate?
* OK, found lookup table for counties and districts, that will be useful! 
* There are counties in the lookup table that are not county councils though, these eight: Greater Manchester, Inner London, Merseyside, Northamptonshire, Outer London, Tyne and Wear, West Midlands, West Yorkshire. 
* Download UK map shapefile: *Local Administrative Units Level 1 (January 2018) Super Generalised Clipped Boundaries in United Kingdom * [this link](https://data.gov.uk/dataset/e892da8a-bf06-4d00-a8fd-a578b30b1dca/local-administrative-units-level-1-january-2018-super-generalised-clipped-boundaries-in-united-kingdom)
* install `sf` package.
* Get basic maps to work, hooray. 
* Probably want ultra generalised, this is too fine. Yeah. 

* OK, now back to outlining Scotland data. 
* OK, so there is crossover in the scottish report, and requires picking up data from the other two reports...
* Check conditional formatting of tables that work in pdf. `condformat` might work. Do they want it?
* Actually cell_spec in kableExtra probably does the trick [see here](https://haozhu233.github.io/kableExtra/awesome_table_in_pdf.pdf). 
* OK, now queries for Ivo. 
* I also now have a much better oveview of how much manual tweaking the reports will require (not too much), so I have the idea of highlighting all the spots that need a manual double check (e.g. in red) so that nothing like that gets accidentally published. 
* Add the four Nottingham workplace levy files to data. Need to try if extracting the tables works there as well. 


# Wednesday 20.3.2019

* OUTLINE the whole project scheme. 
* Try extracting the WPL data. No, it doens't work. There are two other tables on the page and this table is too small I guess, or sth, so it will have to be manually input. 
* Actually, I need to have a look at Wales quickly before I do this. For 2017/18
* OK, summary looks cool: income, expenditure and total transport as well, all match
* Participation in the *Wales Penalty Processing Partnership* and councils where "on-street parking controlled by Gwent Police who are planning to transfer it to the
councils" probably requires an external source, this is in a map legend. 
* Population data is available on same platform [on this link](https://statswales.gov.wales/Catalogue/Population-and-Migration/Population/Estimates/Local-Authority/populationestimates-by-localauthority-year)
* There is additional penalty charge notice data, but that seems to be two years behind i.e. the 17/18 report has data for 15/16
* source for PCNs [is here](https://www.trafficpenaltytribunal.gov.uk/Publications/)
* Unfortunately `tabulizer` does not extract the tables properly. 
* meanwhile have a look at importing json objects..
* OK, so figured out how to extract the json file, and even the table, but that's only the first 1000 records. In order to get what I want I need to query it. 
* hmm, ok, massive issues with fromJSON giving different results each time. If i don't figure it out, then it will have to me manual downloading of csv files. Not the worst thing in the world, it's still probably better than the ENgland and Scotland data..

# Thursday, 21.3.2019

* created json-reprex.Rmd file, tested by Anneka and Martin as well, all get same non-deterministic results. Posted on rstudio community, tomorrow will crosspost on stackoverflow if there isn't any solution. 
* OK, start Wales outline including replies from Ivo. 
* worry about tables being too large. [this stackoverflow answer](https://stackoverflow.com/questions/44490209/how-to-change-font-size-of-table-in-rmarkdown-latex-and-pdf) seems useful
* OK, Wales outline complete.
* Now back to plotting out the whole thing. 
* Download Wales data. csvs directly from the [wales stats website](https://statswales.gov.wales/Catalogue/Local-Government/Finance/Revenue/Transport/RoadsAndTransportRevenueExpenditure-by-authority).
* cross-post the question to [stackoverlfow](https://stackoverflow.com/questions/55277363/r-extracting-json-data-from-an-odata-api-gives-inconsistent-results)

**Downloading Wales Data**

* Export to .csv, without headers, without metadata!
* Gross Expenditure X Parking of vehicles -> wal-exp-17-18.csv [link](https://statswales.gov.wales/v/FMKX)
* Total Income X Parking of vehicles -> wal-inc-17-18.csv [link](https://statswales.gov.wales/v/FMKY)
* Net current cost X Total transport planning, highways, rows and transport -> wal-trans-17-18.csv [link](https://statswales.gov.wales/v/FMKW)

**Consolidating all data**

* Start new file `02-import-data-original.R`
* Design table that will accommodate all 3 countries. 
* figure out how to rename all files in a folder
* `for file in *; do mv "$file" "$(basename "$file").orig"; done;` this didn't work
* `rename 's/\.orig$//' *.orig` this fixed it. 
* haha `for file in *; do mv "$file" "$orig.(basename "$file")"; done;` also fucked it up
* christ, anyway, now manually fixed..

**MASTER TABLE**

* Start by listing all variables required
* Start by importing Wales data
* Decide that the year variable will simply be the first year e.g. for 13/14 it is 2013. Anything can be done with that if needed. 
* Wales data done!
* Scotland Excel files. OK, so looks like cell-specification for readxl cannot handle noncontiguous cells. 
* Also cannot handle single cells - they are treated as the column header.. just leads to ugly code.
* Now to loop everything it would be nice to have all the data in the meta summary tables, including the year (not fiscal year) and the file name. So I'll fix that 
* A, ffs, the name of the local authority also changes cell, and in 16/17 doesn't even have its own cell
* OK, it's not pretty, but it's working: Scotland income and expenditure original data is done!
* Next up: Scotland PCN data

# Friday 22.3.2019

OK, back to the Scotland PNC data scraped from the pdf

* Becasue the 13-16 data is aleady transcribed in the old Leibling reports, i can try using tabulizer on them instead of dealing with the scanned pdf file. Actually, no they're not htere, and it isn't even important. 
* Next the PCN tables with tabulizer
* Nah, actually these all have to be written as funcitons, so they can be reused..
* So extra file with functions now. Which will be reused in the templates
* OK, so extracting PCN numbers. The reusable funciton will only pick out the last year. But I also need to pick out the previous years. So I need a function that picks one or more columns based on the year passed as an argument?
* And of course the numbers have commas in them, so they need to be regexed to become numeric. Actually remove all non-numeric characters. 
* OK, PCN tables done, phew. 
* Next, PCN income from pdf
* OK, now all the tables from the pdfs are done
* Merge them by year, for 14 and 15 there is only one, and there are three for the years 16 and 17
* Then merge all the pdf tables together
* The add the excel data.
* Ah, there are some spaces in the authority names.. in the DPE tables. Fixed
* Additionally five LAs have non-standard name spellings. Need to figure out which ones are standard.. 
* Additionally there is an empty row in the ie table. Damn, this is getting kludgy..
* OK, no3 there is a funciton for changing spellings of scottish LAs, I'll add it to all the funcitons. Fixed
* Now go back to scotland excel import and rewrite as funcitons. I mean move them to the funcitons.R file 
* OK, all of scotland works now, there are only some column type issues . fixed
* Oh, and welsh income is negative .

** ENGLAND IMPORT ORIGINAL DATA**

* First add actual file names to the metadata table. 
* Also, start with 2009, not 2008, because there were 388 LAs then
* So the trick now is to write code to import the original data that will also be useful for updating new data for RAC..
* Turns out the columns with the la names and classes also change from one year to another, have to add them to the metadata
* WHY doesn't this work? Because one cell has "..." in it instead of numbers..
* FFS, ok, this now works for expend.on and expend. off. Now extend to incomes as well. Done.

# Satyrday 23.3.2019

* prealocating a data.frame does not need to list columns, this are small applications anyway, so it's not necessary to worry about efficiency. 
* Now add the totals for ENgland, transport and PCN totals, so only one row for the whole country, for each year. `auth.type` classed as "X"
* Now again, because these are single cells, they get exported as the column headers..Same as the scotland data. 
* Totals import OK.
* Forgot to add country var to England. OK.
* Add the penalty ranges to the I.E. outturn code as well. This possibly requires checking if the data is there..because it's only there for the last three years.  OK.
* Remove authorities we don't need. That's all the ones with an O type, except ones with Naitonal park in the name?OK
* Congestion charges. 
* OK, added congestion charges from the main otturn import, so the whole column is imported for everyone, it doesn't matter, since we only use Greater London. 
* But now i see that some other authorities are kept, ones with WM and YH, and one that's even n/a, this is all 2014 data...Ah, I had the auth.name and auth.type wrong in the metadata, fixed.
* Double check no of authorities: 9 \* 353 = 3177, that's perfect! In addition also 9\* Greater London and  The national parks, 9 of them each year, except in 2008/09, so that's another 80 records, total of 3266 records. 

* Budget data next
* actually the auth.name columns change as well, so need to add them to the metadata. * Also have to add file.names to the metadata. OK
* Budget data all OK. 
* Manual input of WPL data OK

** Merge England **

* Full_join not working - too many rows result.. is it a name thing?
* Yeah, in 2014 the outturn data e.g. says "Worcestershire CC" instead of "Worcestershire" etc.. SO probably safest thing to do is to remove all capitalised two letter words at the end of `auth.name` with some regex magic. or three letter words. 
* Still 30 doubles... variant spellings. 
* SO new FunEnglandFixNames for manually changing names...

* so 3266 authorities in the outturn data, and another 366 from the budget data, since it has an extra year, and finally 4 wpl years plus 9 england totals = 3642 england rows.
* plus scotland and wales is 4046.
* DONE

# Sunday 24.3.2019

* Change Scotland lookup tables to the same style as the England one. OK
* move both to separete rds files. OK
* rename data sources file to 00-manual-data-input.R. OIK
* move the .rds files for metadata into /data/01-raw. OK
* also rename all of these to start with orig. OK. 
* ToDo : Wales doens't have a metadata file, should update that 
* ToDo: for consistency, all the original data files names should end with the single year, not the double ones as they do now.. that means also changing all the metadata...
* Clean up code to read all meta .rds files at once? OK
* Looks like this mass import using assign and lapply is changing the character columns into factors. fixed (stringsasfactors option was off in 00-manual-data-input.R)
* move WPL manual entry to 00-manual-data-input.R . OK
* Also add year to the manual WPL entry instead of wpl.year, because it gets added using bind.row anyway. Oh, actually it should get added using full_join, so they are not separate rows. OK
* And now full join the wpl data by auth.name and year. but wpl logical actually doesn't need to be there anymore, you can tell who has wpl simply if they have a wpl.income value. OK
* So now there are 4 fewer rows than before. 
* so 3266 authorities in the outturn data, and another 366 from the budget data, since it has an extra year, plus 9 england totals = 3638 england rows.
* Scotland has 6 years of i.e. data * 32 = 192, pdf data is for 96 of the same rows, so 192 in total. 
* Wales has 308 rows, that's 14 years by 22 LAs. 
* Now that should be 3638 + 192 + 308 = 4138.
* OK!!

** start wales report template **
* how do i get the year into the title?
* get colours to work (include in header)
* now, i import the whole table at the start, from rds?
* where are the surpluses calculated? maybe i should do all the calculations in the reports.Let's try that. 
* creating tables..
  + empty cells?
  + column headers that are numbers (2018-19)
  + hlines
  + alignment
  + multirows 
  + alingment if you have mutlirows...





### Wales (based on 17/18) #####################################################

#### 1. Introduction

* Text, only fiscal year
* Text with named councils that have free parking, manual input. 

#### 2. Summary

* Table 1 based on Wales statistics data, all checks out
* Text based on table 1
* Crossover value from England report.
* Figure 1 from table 1
* Map, is a map, but potentially unnecessary.

#### 3. Income (there is no separate section?)

* text based on table 2, 
* Some conditionals. 
* Sentence on proportion of the population.. Do I have to get the data for that?
* Paragraph on income per population removed, since data also removed.
* Table 2, data from Wales statistics data, ignore the population measures, cf Ivo: it is a meaningless measure

#### 3.1 PNCs

This data is massively time lagged, Ivo suggested removing it?

#### 4. Expenditures

* Text based on table 4, some conditionals too much for automation
* Table 4 based on Wales stats data. 

#### 5. Surpluses

* Table based on Tables 3 and4
* Text based on table
* Some text has explanations for the reducitons/increases that are too tricky to write conditionally. But could potentially be done. 

#### 6. reporting

* Non automatable, can leave skeleton text/table if required. 

### Scotland (based on 16/17) ###################################################

* Mainly pure text chunk.
* Available data: fiscal year, link to income and expenditure data, link to PNC data, link to SPRECC report with previous data. 
* Paragraph on data availability on Penalty Charne Notices, incl. source, which is a scanned pdf...


#### 1. Introduction

##### Text

* Text based on table 1. Conditional tree could get complicated as the table becomes simpler, but can make it simple I think. 

##### Table 1

* exact same table as in pcn.pdf, can be extracted directly from pdf and cleaned up. 

##### Text

* Pure text

#### 2. Summary 

##### Text

* based on table 2. Conditoinal tree must be able to describe temporal trend..

##### Table 2

* Based on first summary sheet in Scotland income and expenditure data files. But it is inconsistent, partially because of Aberdeen, but something else is also going on..
* Based also on total transport expenditure from same sheet, but numbers don't match. 
##### Figure 1

* Based on Table 2, OK

##### Table 3

* Based on summary data in table 2, BUT also data for England and Wales, which historically is already available by the time Scotland's report is due. 

##### Table 4

* Again, crossover with other two countries, additionally this one is 12/13 to 16/17, not sure what to do next window wise. 

##### Text

* Based on calculation based on data used in table 4. 

#### 3. Income

##### Text

* Based on data in table 5

##### Table 5

* Based on data in income and expendidure files, except for Aberdeen City.. And possibly some other local authorities?
* Also includes data from Table 1, i.e. the pdf scraped table.

##### Text

* Text based on table 6.



##### Table 6

* NUmbers of PNCs are from the table scraped in the pdf. 
* Additionally the calculated average cost of a PNC is from the income table also scraped from the PNC. 
* 3 year window in 16/17


##### Text

* Based on numbers in table 7

##### Table 7

* Proportions calculated from PCN data in pdf, and income data from xls. 
* Except for Aberdeen..
* Including crossover with England data

#### 4. Expenditure

##### Text

* Text based on table 8, potentially tricky conditional tree...

##### Table 8

* Expenditure data from excel files only. 
* Proportion calculated from income also from xls files. 
* Additionally DPE in operaction data from first scraped table from pdf. 

#### 5. Surpluses

##### Text

* Text based on nice conditional tree from table 9
* Also national ranking!!

##### Table 9
 * Surplus data calculated from incomes and expenditures in xls
 * changes also. 
 * again DPE data drom table 1 in the pdf
 
##### Table 10

* Contribution of surplus towards total transport expenditure. 
* OK, but which one is the total transport expenditure!?

#### 6 Comparison between Local Government Finance figures and Transport Scotland decriminalised parking enforcement figures

* OOh, interesting! But should it really be in this report, haha
* So combine data from xls and pdf and look at discrepancies, which should be mainly off street parking, but maybe are not just that. 

#### Appendix

* Map based on Table 1

### England ######################################################################

#### 1. Introduction

* Mainly pure text chunk.
* Available data: fisc.year
* Missing data: national parks, Notthingham workplace parking levy? (17/18)

#### 2. Summary

##### Table 1 - Parking income and expenditure England

* Unit: whole country
* Available data:
  + Off-street: expenditures (sum from LA tables)
  + Off-street: incomes (sum from LA tables)
  + On-street: expenditures (sum from LA tables)
  + On-street: incomes (sum from LA tables)
  + On-street: penalties - single cell on summary sheet
  + Net expenditure on transport - single cell on summary sheet
  + Budget estimates for next year
* That's all, everything else is calculated from this





##### Text

* Conditional tree based on data from Table 1. 

##### Figure 1

* Simple line chart based on data from Table 1.

##### Table 2

* Data from Table 1 for current year, split by London and non-London. 

##### Text

* Conditional tree based on data from Table 2.

#### 3. Income

##### Text

* Conditional tree based on data from Tables 1 and 2
* Includes footnote on penalty tarrifs. 

#### 4. Expenditure

##### Text

* Conditional tree based on data from Tables 1 and 2

#### 5. Surpluses

##### Text

* Conditional tree based on data from Tables 1 and 2
* Additionally there is the total for on national parks, that data is also available
* Missing data: the total for Nottingham workplace levy. 

##### Table 3a surpluses for London councils

* Individual LA data for 33 London councils

##### Table 3b surpluses for top 20 non London councils

* Individual LA data for 33 London councils

##### Text

* Conditional tree based on data from Tables 3a and 3b

#### 6. Comparison with budgets for2017-18and 2018-19

* Conditional text based on comparison of indovidual LA surpluses with individual LA budgets

#### 7. Congestion charge

##### Text 
* Conditional text based on table below

##### Table
* Simple table based on data from outturn table. 

#### Appendix 1

* Table of all LA surpluses for 5 years, alphabetical 

#### Appendix 2

* Table of all LA surpluses for 5 years, by surplus size. 






# Appendix 1
## links to all reports online
```{r appendix, child = 'app1.Rmd'}
```

# Appendix 2
## data overview - England
```{r appendix, child = 'app2.Rmd'}
```

# Appendix 2
## data overview - Scotland
```{r appendix, child = 'app3.Rmd'}
```